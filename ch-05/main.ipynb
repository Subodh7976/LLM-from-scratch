{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from chapter04 import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, \n",
    "    \"context_length\": 256, \n",
    "    \"emb_dim\": 768, \n",
    "    \"n_heads\": 12, \n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1, \n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you�442rued infancy marrow orcs controlledavanGood crest\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from chapter04 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model, \n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10, \n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], \n",
    "                       [40, 1107, 588]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345], \n",
    "                        [588, 428, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[21391],\n",
      "         [44167],\n",
      "         [11026]],\n",
      "\n",
      "        [[48752],\n",
      "         [25931],\n",
      "         [19647]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  intentional'> fleet\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([4.2580e-06, 7.4673e-05, 8.3142e-06])\n",
      "Text 2: tensor([1.9969e-05, 1.0473e-05, 6.8551e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-12.3667,  -9.5024, -11.6975, -10.8213, -11.4667, -11.8905])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.2909)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2909)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = -1 * avg_log_probas\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2909)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(80086.1562)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter02 import create_dataloader_v1\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data, \n",
    "    batch_size=2, \n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True, \n",
    "    shuffle=True \n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data, \n",
    "    batch_size=2, \n",
    "    max_length=GPT_CONFIG_124M['context_length'], \n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break \n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.999631987677681\n",
      "Validation loss: 11.037252426147461\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, \n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, \n",
    "                       num_epochs, eval_freq, eval_iter, start_context):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter \n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "                \n",
    "        generate_and_print_sample(\n",
    "            model, train_loader.dataset.tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.058, Val loss 10.118\n",
      "Ep 1 (Step 000005): Train loss 7.925, Val loss 8.336\n",
      "Every effort moves you,,,,,                                             \n",
      "Ep 2 (Step 000010): Train loss 6.670, Val loss 7.070\n",
      "Ep 2 (Step 000015): Train loss 6.003, Val loss 6.623\n",
      "Every effort moves you, the, the, the, the, the, the, the, the,, the, the, the, the, the, the,, the, the,, the, the, the, the, the, the, the,\n",
      "Ep 3 (Step 000020): Train loss 5.871, Val loss 6.551\n",
      "Ep 3 (Step 000025): Train loss 4.975, Val loss 6.605\n",
      "Every effort moves you aburn was the a little, and he had theI. Gisburn was a of theI, and I had theI to the last, and I had the, and he had a of theI. Gisburn--I.\n",
      "Ep 4 (Step 000030): Train loss 5.202, Val loss 6.525\n",
      "Ep 4 (Step 000035): Train loss 4.748, Val loss 6.371\n",
      "Every effort moves you a little, and--and I had been--and I had the last of the last, I had been to have to the last to the last, I had been his, I had been he had been his own the last, I had been\n",
      "Ep 5 (Step 000040): Train loss 4.011, Val loss 6.309\n",
      "Every effort moves you know,\" was one of the picture--I felt, and uncertain.  \"I was no, and to see it was the picture was.  \"--I, and.  \"--as the fact, and he was his\n",
      "Ep 6 (Step 000045): Train loss 3.816, Val loss 6.282\n",
      "Ep 6 (Step 000050): Train loss 3.228, Val loss 6.253\n",
      "Every effort moves you know,\" was one of the axioms he had been his pictures. \"I looked up and I had been his pictures. \"Oh, and his pictures.   \"I had the donkey. \"strong.   \n",
      "Ep 7 (Step 000055): Train loss 3.068, Val loss 6.316\n",
      "Ep 7 (Step 000060): Train loss 2.369, Val loss 6.318\n",
      "Every effort moves you in the was one of the axioms he had a good- of a. Gisburn's an!     \"Oh, and his pictures. Gisburn--as I had been the; and Mrs. Gis\n",
      "Ep 8 (Step 000065): Train loss 1.835, Val loss 6.356\n",
      "Ep 8 (Step 000070): Train loss 1.280, Val loss 6.359\n",
      "Every effort moves you in the inevitable gar that my dear.  \"I turned to me--so it was no great surprise to me to me. \"I turned back his glory, as his pictures--the I was, and were, and in the first\n",
      "Ep 9 (Step 000075): Train loss 0.724, Val loss 6.377\n",
      "Ep 9 (Step 000080): Train loss 0.974, Val loss 6.477\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"Once, when I looked up, I seemed to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.567, Val loss 6.532\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, and I turned, my eye fell on a small picture\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, \n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1, \n",
    "    start_context=\"Every effort moves you\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model, \n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer), \n",
    "    max_new_tokens=25, \n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    'closer': 0, \n",
    "    'every': 1, \n",
    "    'effort': 2, \n",
    "    'forward': 3, \n",
    "    'inches': 4, \n",
    "    'moves': 5, \n",
    "    'pizza': 6, \n",
    "    'toward': 7, \n",
    "    'you': 8\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "560 x forward\n",
      "4 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "370 x toward\n",
      "4 x you\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(42)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sample_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sample_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print(print_sampled_tokens(probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], \n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature, top_k=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, \n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits \n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "He me you.\"\n",
      "\" to face the irony. But in\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model, \n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15, \n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k=25, \n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'model_state_dict': model.state_dict(), \n",
    "#     \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "# }, \"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(\"model_and_checkpoint.pth\")\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x202c260f250>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 38.5kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 545kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 30.0kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [04:26<00:00, 1.87MiB/s]   \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 2.58MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 338kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 241kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size='124M', models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params['wte'])\n",
    "print(\"Token embedding weight tensor dimensions:\", params['wte'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG['context_length'] = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params['blocks'])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params['blocks'][b]['attn']['c_attn'])['w'], \n",
    "            3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    " \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    " \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    " \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    " \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    " \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you into what seems to you that will help to change everything for everyone. There is no good, nor an easy escape from your\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt, \n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer), \n",
    "    max_new_tokens=25, \n",
    "    context_size=NEW_CONFIG['context_length'], \n",
    "    top_k=50, \n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
